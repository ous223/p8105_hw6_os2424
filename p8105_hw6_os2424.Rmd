---
title: "HW6"
author: "Ou Sha"
date: "2023-12-02"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(purrr)
library(MASS)
library(modelr)
```

# Problem 1
```{r}
# import data
homi <- read.csv("./data/homicide-data.csv")
```

```{r, warning=FALSE}
# clean data 
homi <- homi|>
  # create city_state variable
  mutate(city_state = str_c(city, state, sep = ", "))|>
  # create binary variable
  mutate(resolved = case_when(disposition == "Closed without arrest" ~ 0,
                          disposition == "Open/No arrest" ~0,
                          disposition == "Closed by arrest" ~ 1))|>
  # omit cities
  filter(!(city_state %in% c("Tulsa, AL", "Dallas, TX", 
                             "Phoenix, AZ", "Kansas City, MO")))|> 
  # limit races
  filter(victim_race %in% c("White", "Black"))|>
  # make age numeric
  mutate(victim_age = as.numeric(victim_age))|>
  dplyr::select(-city, - state, -disposition)
```

```{r}
# use the glm function to fit a logistic regression 
md_glm <- homi|> 
  filter(city_state == "Baltimore, MD")|> 
  dplyr::select(city_state, resolved, victim_age, victim_sex, victim_race)|>
  glm(resolved ~ victim_age + victim_race + victim_sex, data = _, family = binomial())
# save the output as an R object
save(md_glm, file = "baltimore_glm.RData")
md_glm|>
  # apply the broom::tidy to this object
  broom::tidy()|> 
  filter(term == "victim_sexMale")|> 
  mutate(OR = exp(estimate),
         OR_upper = exp(estimate + 1.96 * std.error),
         OR_lower = exp(estimate - 1.96 * std.error))|>
  dplyr::select(estimate, OR, OR_lower, OR_upper) |>
  knitr::kable(digits = 3)
```

```{r}
# run glm for each city
all_glm <- homi|>
  nest(city = -city_state) |> 
  mutate(log_re = map(city, \(x) glm(resolved ~ victim_age + victim_sex + victim_race, 
                             family = binomial(), data = x)),
         tidy= map(log_re, broom::tidy))|> 
  unnest(tidy)|>
  filter(term == "victim_sexMale")|> 
  mutate(OR = exp(estimate),
         OR_upper = exp(estimate + 1.96 * std.error),
         OR_lower = exp(estimate - 1.96 * std.error))|>
  dplyr::select(city_state, estimate, OR, OR_lower, OR_upper)
all_glm|>
  knitr::kable(digits = 3)
# create plot 
all_glm|>
  # Organize cities according to estimated OR
  ggplot(aes(x = OR, y = fct_reorder(city_state,OR))) + 
  geom_point() + 
  geom_errorbar(aes(xmin = OR_lower, xmax = OR_upper))+
  labs(x = "odds ratio", y = "cities", title = "Estimated ORs and CIs for each city")
```

Based on the plot, New York, NY has the smallest estimated odds ratio and Albuquerque, NM has the largest estimated odds ratio with a larger CI.

# Problem 2
```{r}
# download data
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  dplyr::select(name, id, everything())
```

```{r, warning=FALSE}
# produce estimate of two quantities
boot_straps <- weather_df |> 
  modelr::bootstrap(n = 5000)|>
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df) ),
    log_b = map(models, broom::tidy),
    r_2 = map(models, broom::glance))|>
  unnest(log_b, r_2)|>
  dplyr::select(.id, term, estimate, r.squared)|>
  filter(term != "(Intercept)")|>
  pivot_wider(names_from = term,
              values_from = estimate)|>
  # get log(beta1 * beta2)
  mutate(log_beta = log(tmin*prcp))
# delete NAs
boot_straps_nNA <- boot_straps|>
  na.omit()
# plot distribution of estimates
par(mfrow=c(1,2))
# r.squared
boot_straps|>
  ggplot(aes(x=r.squared))+
  geom_density() +
  labs(x = "estimated r.squared",
       title = "distribution of estimated r.squared")
# log
boot_straps_nNA|>
  ggplot(aes(x=log_beta))+
  geom_density() +
  labs(x = "estimated log(b1*b2)",
       title = "distribution of estimated log(b1*b2)")
```

The distribution of r^2 is approximately a slightly left skewed normal distribution. All r62 values are close to 1 which indicates that a strong linear relationship and the model we use is appropriate. \
The distribution of log(beta) is left skewed with some outliers at the smaller edge.

```{r}
# CI for r squared
quantile(pull(boot_straps, r.squared), probs = c(0.025,0.975))|>
  knitr::kable()
# CI for log
quantile(pull(boot_straps_nNA, log_beta), probs = c(0.025,0.975))|>
  knitr::kable()
```

# Problem 3
```{r}
# import data
birthwt <- read_csv("data/birthweight.csv")
# clean data
birthwt <- birthwt|>
  janitor::clean_names()|>
  mutate(babysex = case_when(babysex ==1 ~"male",
                             babysex ==2 ~"female"),
         frace = case_when(frace ==1 ~"White",
                           frace ==2 ~"Black",
                           frace ==3 ~"Asian",
                           frace ==4 ~"Puerto Rican",
                           frace ==8 ~"Other",
                           frace ==9 ~"Unknown"),
         malform = case_when(malform ==0 ~"absent",
                             malform ==1 ~"present"),
         mrace = case_when(mrace ==1 ~"White",
                           mrace ==2 ~"Black",
                           mrace ==3 ~"Asian",
                           mrace ==4 ~"Puerto Rican",
                           mrace ==8 ~"Other"))
# check for NA
sum(is.na(birthwt))
```
Based on a paper analyzing factors affecting birth weight of a newborn , I decided to use 
baby's sex, baby's length at birth, mother's weight at delivery, gestational age in weeks, father's race, presence of malformations that could affect weight, mother's age at delivery, average number of cigarettes smoked per day during pregnancy, and mother's weight gain during pregnancy as factors to propose a model for birth weight. \

paper reference: Metgud CS, Naik VA, Mallapur MD. Factors affecting birth weight of a newborn--a community based study in rural Karnataka, India. PLoS One. 2012;7(7):e40040. doi:10.1371/journal.pone.0040040
```{r}
#Propose a regression model for birthweight
m1 <- birthwt|>
  lm(bwt ~ babysex + blength+ gaweeks + frace+malform + momage + smoken + wtgain, data = _)
# show a plot of model residuals against fitted values
birthwt|>
  add_predictions(m1)|>
  add_residuals(m1)|>
  ggplot(aes(x = pred, y = resid))+
  geom_point()
```

Based on the plot, there is no relationship between the residuals and fitted values. 

```{r}
# compare model to two others
m2 <- birthwt|>
  lm(bwt ~ blength + gaweeks, data = _)
m3 <- birthwt|>
  lm(bwt ~ bhead * blength * babysex, data = _)
# cross-validated prediction error
cv <- crossv_mc(birthwt, 100)|>
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))|>
  mutate(
    f1  = map(train, ~m1),
    f2  = map(train, ~m2),
    f3  = map(train, ~m3))|> 
  mutate(
    rmse_1 = map2_dbl(f1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_2 = map2_dbl(f2, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_3 = map2_dbl(f3, test, \(mod, df) rmse(model = mod, data = df)))
cv|> 
  dplyr::select(starts_with("rmse"))|> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

Based on the plot, the intersection model is the best one with the smallest RMSE. The proposed model is better than the main model, which has the largest RMSE. 